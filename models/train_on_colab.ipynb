{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# üöÄ ML Footprint Prediction - Google Colab GPU Training\n",
                "\n",
                "> Multi-output XGBoost training on Google Colab's free GPU\n",
                "\n",
                "---\n",
                "\n",
                "## üìã Setup Instructions\n",
                "\n",
                "### 1. Enable GPU Runtime\n",
                "- Click **Runtime** ‚Üí **Change runtime type**\n",
                "- Set **Hardware accelerator** to **GPU** (T4 recommended)\n",
                "- Click **Save**\n",
                "\n",
                "### 2. Upload Your Data\n",
                "You'll need to upload:\n",
                "- `train.csv` (from `data/data_splitter/output/`)\n",
                "- `validate.csv` (from `data/data_splitter/output/`)\n",
                "- `material_dataset_final.csv` (from `data/data_calculations/input/`)\n",
                "\n",
                "### 3. Run All Cells\n",
                "- Click **Runtime** ‚Üí **Run all**\n",
                "- Wait for training to complete (~30-60 min)\n",
                "- Download trained model at the end\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup"
            },
            "source": [
                "## üîß Step 1: Environment Setup\n",
                "\n",
                "Install required packages and clone your repository."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q xgboost matplotlib seaborn joblib\n",
                "\n",
                "# Verify GPU availability\n",
                "import subprocess\n",
                "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
                "print(\"GPU Information:\")\n",
                "print(result.stdout)\n",
                "\n",
                "# Check XGBoost GPU support\n",
                "import xgboost as xgb\n",
                "print(f\"\\nXGBoost version: {xgb.__version__}\")\n",
                "print(f\"GPU available: {xgb.dask != None}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "clone"
            },
            "source": [
                "## üì¶ Step 2: Clone Repository or Upload Code\n",
                "\n",
                "**Option A**: Clone from GitHub (if you have a repository)\n",
                "\n",
                "**Option B**: Upload code manually (see below)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "# Option A: Clone from GitHub (replace with your repo URL)\n",
                "# !git clone https://github.com/your-username/bulk_product_generator.git\n",
                "# %cd bulk_product_generator/models\n",
                "\n",
                "# Option B: Create directory structure manually\n",
                "!mkdir -p models/src\n",
                "!mkdir -p models/data\n",
                "!mkdir -p models/logs\n",
                "!mkdir -p models/saved\n",
                "%cd models\n",
                "\n",
                "print(\"‚úì Directory structure created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "upload_code"
            },
            "source": [
                "### Upload Python Source Files\n",
                "\n",
                "If you didn't clone from GitHub, upload these files from your local `models/src/` directory:\n",
                "- `__init__.py`\n",
                "- `config.py`\n",
                "- `data_loader.py`\n",
                "- `formula_features.py`\n",
                "- `preprocessor.py`\n",
                "- `trainer.py`\n",
                "- `evaluator.py`\n",
                "- `utils.py`\n",
                "\n",
                "And from `models/`:\n",
                "- `train_max_accuracy.py`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "upload_src"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "# Upload all Python source files to src/\n",
                "print(\"Upload all .py files from your local models/src/ directory:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Move files to src/ directory\n",
                "for filename in uploaded.keys():\n",
                "    if filename.startswith('src_'):  # If you prefix with 'src_'\n",
                "        target = f\"src/{filename[4:]}\"\n",
                "    elif filename == 'train_max_accuracy.py':\n",
                "        target = filename\n",
                "    else:\n",
                "        target = f\"src/{filename}\"\n",
                "    \n",
                "    !mv {filename} {target}\n",
                "    print(f\"‚úì Moved {filename} ‚Üí {target}\")\n",
                "\n",
                "print(\"\\n‚úì All source files uploaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "upload_data"
            },
            "source": [
                "## üìä Step 3: Upload Data Files\n",
                "\n",
                "Upload your training data and material factors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "upload_data_files"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import shutil\n",
                "\n",
                "print(\"Upload train.csv, validate.csv, and material_dataset_final.csv\")\n",
                "print(\"NOTE: These files may be large (train.csv ~500MB). Upload may take a few minutes.\")\n",
                "print(\"\")\n",
                "\n",
                "uploaded_data = files.upload()\n",
                "\n",
                "# Move to data directory\n",
                "for filename in uploaded_data.keys():\n",
                "    shutil.move(filename, f\"data/{filename}\")\n",
                "    print(f\"‚úì Moved {filename} ‚Üí data/\")\n",
                "\n",
                "# Verify files\n",
                "print(\"\\nData files in data/:\")\n",
                "!ls -lh data/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "verify"
            },
            "source": [
                "## ‚úÖ Step 4: Verify Setup\n",
                "\n",
                "Check that everything is ready for training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "verify_setup"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Check source files\n",
                "required_src = [\n",
                "    'src/__init__.py',\n",
                "    'src/config.py',\n",
                "    'src/data_loader.py',\n",
                "    'src/formula_features.py',\n",
                "    'src/preprocessor.py',\n",
                "    'src/trainer.py',\n",
                "    'src/evaluator.py',\n",
                "    'src/utils.py',\n",
                "    'train_max_accuracy.py'\n",
                "]\n",
                "\n",
                "print(\"Checking source files:\")\n",
                "all_src_ok = True\n",
                "for file in required_src:\n",
                "    exists = os.path.exists(file)\n",
                "    status = \"‚úì\" if exists else \"‚úó\"\n",
                "    print(f\"  {status} {file}\")\n",
                "    if not exists:\n",
                "        all_src_ok = False\n",
                "\n",
                "# Check data files\n",
                "required_data = [\n",
                "    'data/train.csv',\n",
                "    'data/validate.csv',\n",
                "    'data/material_dataset_final.csv'\n",
                "]\n",
                "\n",
                "print(\"\\nChecking data files:\")\n",
                "all_data_ok = True\n",
                "for file in required_data:\n",
                "    exists = os.path.exists(file)\n",
                "    status = \"‚úì\" if exists else \"‚úó\"\n",
                "    size = os.path.getsize(file) / (1024*1024) if exists else 0\n",
                "    print(f\"  {status} {file} ({size:.1f} MB)\" if exists else f\"  {status} {file}\")\n",
                "    if not exists:\n",
                "        all_data_ok = False\n",
                "\n",
                "if all_src_ok and all_data_ok:\n",
                "    print(\"\\n‚úÖ All files present! Ready to train.\")\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è  Some files missing. Please upload them before proceeding.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "update_paths"
            },
            "source": [
                "## üîß Step 5: Update Data Paths for Colab\n",
                "\n",
                "Modify the training script to use Colab's file paths."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "configure_paths"
            },
            "outputs": [],
            "source": [
                "# Update data_loader.py to use Colab paths\n",
                "with open('src/data_loader.py', 'r') as f:\n",
                "    content = f.read()\n",
                "\n",
                "# Replace default paths with Colab paths\n",
                "content = content.replace(\n",
                "    \"'/home/tr4moryp/Projects/bulk_product_generator/data/data_splitter/output/train.csv'\",\n",
                "    \"'data/train.csv'\"\n",
                ")\n",
                "content = content.replace(\n",
                "    \"'/home/tr4moryp/Projects/bulk_product_generator/data/data_splitter/output/validate.csv'\",\n",
                "    \"'data/validate.csv'\"\n",
                ")\n",
                "content = content.replace(\n",
                "    \"'/home/tr4moryp/Projects/bulk_product_generator/data/data_calculations/input/material_dataset_final.csv'\",\n",
                "    \"'data/material_dataset_final.csv'\"\n",
                ")\n",
                "\n",
                "with open('src/data_loader.py', 'w') as f:\n",
                "    f.write(content)\n",
                "\n",
                "print(\"‚úì Paths updated for Google Colab\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "train_header"
            },
            "source": [
                "## üéØ Step 6: Start Training\n",
                "\n",
                "### Training Configuration\n",
                "\n",
                "This will run the 3-phase training pipeline:\n",
                "1. **Phase 1**: Baseline training (2000 rounds, ~15-20 min)\n",
                "2. **Phase 2**: Evaluation & robustness testing (~10-15 min)\n",
                "3. **Phase 3**: Augmented retraining if needed (~20-30 min)\n",
                "\n",
                "**Total time**: 30-60 minutes on GPU\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "train_full",
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# Run full training pipeline\n",
                "!python train_max_accuracy.py \\\n",
                "  --tree-method gpu_hist \\\n",
                "  --save-dir saved/colab_training\n",
                "\n",
                "# Note: Remove the line break (\\) if running on Windows"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "train_quick"
            },
            "source": [
                "### Quick Test (Optional)\n",
                "\n",
                "If you want to test with a smaller dataset first:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "train_quick_exec"
            },
            "outputs": [],
            "source": [
                "# Quick test with 10K samples (5-10 min)\n",
                "# !python train_max_accuracy.py --sample-size 10000 --save-dir saved/quick_test"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "results_header"
            },
            "source": [
                "## üìä Step 7: View Results\n",
                "\n",
                "Check training logs and evaluation metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "view_logs"
            },
            "outputs": [],
            "source": [
                "# View last 100 lines of training log\n",
                "!tail -100 logs/training_max_accuracy.log"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "view_metrics"
            },
            "outputs": [],
            "source": [
                "# Display evaluation report\n",
                "import json\n",
                "\n",
                "report_path = 'saved/colab_training/baseline/evaluation/evaluation_report.json'\n",
                "with open(report_path, 'r') as f:\n",
                "    report = json.load(f)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"EVALUATION RESULTS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "if 'baseline' in report:\n",
                "    print(\"\\nBaseline Performance (Complete Data):\")\n",
                "    for target in ['carbon_material', 'carbon_transport', 'carbon_total', 'water_total']:\n",
                "        if target in report['baseline']:\n",
                "            metrics = report['baseline'][target]\n",
                "            print(f\"\\n{target}:\")\n",
                "            print(f\"  MAE:  {metrics['mae']:.4f}\")\n",
                "            print(f\"  RMSE: {metrics['rmse']:.4f}\")\n",
                "            print(f\"  R¬≤:   {metrics['r2']:.4f}\")\n",
                "\n",
                "if 'robustness' in report:\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"Robustness (30% Missing Data):\")\n",
                "    for r in report['robustness']:\n",
                "        if abs(r['missing_pct'] - 0.3) < 0.01:\n",
                "            print(f\"  carbon_total MAE: {r['carbon_total_mae']:.4f}\")\n",
                "            print(f\"  carbon_total R¬≤:  {r['carbon_total_r2']:.4f}\")\n",
                "            break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "show_plots"
            },
            "outputs": [],
            "source": [
                "# Display robustness curve\n",
                "from IPython.display import Image, display\n",
                "import os\n",
                "\n",
                "plot_path = 'saved/colab_training/baseline/evaluation/robustness_curves.png'\n",
                "if os.path.exists(plot_path):\n",
                "    display(Image(filename=plot_path))\n",
                "else:\n",
                "    print(\"Plot not found. Training may still be in progress.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download_header"
            },
            "source": [
                "## üíæ Step 8: Download Trained Model\n",
                "\n",
                "Download the trained model to your local machine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "zip_model"
            },
            "outputs": [],
            "source": [
                "# Create ZIP archive of trained model\n",
                "!zip -r trained_model.zip saved/colab_training/baseline/ logs/\n",
                "\n",
                "print(\"\\n‚úì Model files zipped\")\n",
                "!ls -lh trained_model.zip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_model"
            },
            "outputs": [],
            "source": [
                "# Download the ZIP file\n",
                "from google.colab import files\n",
                "\n",
                "print(\"Downloading trained model...\")\n",
                "files.download('trained_model.zip')\n",
                "print(\"\\n‚úì Download complete!\")\n",
                "print(\"\\nExtract the ZIP file on your local machine:\")\n",
                "print(\"  - saved/colab_training/baseline/ ‚Üí Contains model files\")\n",
                "print(\"  - logs/ ‚Üí Contains training logs\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "usage_header"
            },
            "source": [
                "## üîÆ Step 9: Test Predictions (Optional)\n",
                "\n",
                "Make predictions on sample data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "test_predict"
            },
            "outputs": [],
            "source": [
                "from src.trainer import FootprintModelTrainer\n",
                "from src.preprocessor import FootprintPreprocessor\n",
                "import pandas as pd\n",
                "\n",
                "# Load trained model\n",
                "trainer = FootprintModelTrainer.load('saved/colab_training/baseline')\n",
                "preprocessor = FootprintPreprocessor.load('saved/colab_training/baseline/preprocessor.pkl')\n",
                "\n",
                "# Load sample from validation set\n",
                "val_df = pd.read_csv('data/validate.csv')\n",
                "X_sample = val_df.head(10)\n",
                "\n",
                "# Prepare features (simplified - normally you'd add formula features too)\n",
                "from src.data_loader import FEATURE_COLUMNS\n",
                "X_features = X_sample[FEATURE_COLUMNS]\n",
                "\n",
                "# Note: In production, you'd need to add formula features and preprocess\n",
                "# This is just a quick demo\n",
                "\n",
                "print(\"Model loaded successfully!\")\n",
                "print(f\"Best iteration: {trainer.model.best_iteration}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "next_steps"
            },
            "source": [
                "## üéâ Training Complete!\n",
                "\n",
                "### Next Steps:\n",
                "\n",
                "1. **Review Results**: Check the evaluation report and plots above\n",
                "2. **Download Model**: The trained model has been zipped and is ready to download\n",
                "3. **Use Locally**: Extract `trained_model.zip` and use for predictions\n",
                "\n",
                "### Model Files Included:\n",
                "- `xgb_model.json` - XGBoost model\n",
                "- `trainer_config.pkl` - Training configuration\n",
                "- `preprocessor.pkl` - Fitted preprocessor\n",
                "- `evaluation_report.json` - Performance metrics\n",
                "- `robustness_curves.png` - Performance plots\n",
                "- Training logs\n",
                "\n",
                "### Expected Performance:\n",
                "- **R¬≤ > 0.90** for all targets (complete data)\n",
                "- **MAE < 0.10 kg CO2e** for carbon predictions\n",
                "- **Physics constraint violation < 0.01**\n",
                "\n",
                "---\n",
                "\n",
                "**Questions or issues?** Check the troubleshooting section in the README.\n"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}